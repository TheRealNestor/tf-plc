"""
Main IR optimizer that orchestrates optimization passes.
"""

import logging
from typing import List, Optional, Dict
from collections import defaultdict
from dataclasses import dataclass

from ..onnx_to_ir.converter import topological_sort
from ..types import NetworkIR
from .base_pass import OptimizationPass
from .passes import (
    RemoveIdentityPass,
    RemoveNoOpReshapePass,
    RemoveRedundantQuantPairPass,
    RemoveWeightDequantPass,
    FuseLinearActivationPass,
    BufferAllocationPass,
    RemoveDropoutPass,
)

logger = logging.getLogger(__name__)

DEFAULT_PASSES: List[OptimizationPass] = [
    RemoveDropoutPass(),
    RemoveIdentityPass(),
    RemoveWeightDequantPass(),
    RemoveNoOpReshapePass(),
    RemoveRedundantQuantPairPass(),
    FuseLinearActivationPass(),
    BufferAllocationPass(),  # Produces code generation hints, doesn't modify IR
]


@dataclass
class OptimizationResult:
    """Result of IR optimization, including optional code generation hints."""

    ir: NetworkIR
    buffer_allocations: Optional[Dict[str, str]] = None  # tensor_name -> buffer_name

    def has_buffer_allocations(self) -> bool:
        """Check if buffer allocations are available."""
        return self.buffer_allocations is not None


class IROptimizer:
    """Applies optimization passes to NetworkIR."""

    def __init__(self, ir: NetworkIR, passes: Optional[List[OptimizationPass]] = None):
        self.ir = ir
        self.passes = passes if passes is not None else DEFAULT_PASSES

    def optimize(self) -> OptimizationResult:
        """
        Apply optimization passes to the IR.

        Returns:
            OptimizationResult containing optimized IR and optional code generation hints
        """
        initial_layer_count = len(self.ir.layers)
        logger.info(f"Starting optimization with {initial_layer_count} layers")

        buffer_allocations = None

        for pass_instance in self.passes:
            logger.info(f"Running pass: {pass_instance.get_name()}")
            pass_instance.optimize(self.ir)

            # Rebuild IR if pass modified the graph structure
            if pass_instance.removed_layers or pass_instance.tensor_mapping:
                self.ir = self._rebuild_ir(
                    pass_instance.removed_layers, pass_instance.tensor_mapping
                )

            # Extract code generation hints (doesn't modify IR)
            if (
                hasattr(pass_instance, "buffer_assignments")
                and pass_instance.buffer_assignments
            ):
                buffer_allocations = {
                    tensor: alloc.buffer_name
                    for tensor, alloc in pass_instance.buffer_assignments.items()
                }
                logger.info(f"Extracted {len(buffer_allocations)} buffer allocations")

        final_layer_count = len(self.ir.layers)
        logger.info(
            f"Optimization complete: {initial_layer_count} -> {final_layer_count} layers "
            f"({initial_layer_count - final_layer_count} removed)"
        )

        return OptimizationResult(ir=self.ir, buffer_allocations=buffer_allocations)

    def _filter_removed_layers(self, removed_layers: set) -> dict:
        """Remove layers marked for deletion."""
        return {
            name: layer
            for name, layer in self.ir.layers.items()
            if name not in removed_layers
        }

    def _follow_tensor_mapping(self, tensor: str, tensor_mapping: dict) -> str:
        """
        Follow tensor mapping chain to find final tensor.

        Handles transitive mappings: A->B, B->C results in A->C
        """
        source = tensor
        while source in tensor_mapping:
            source = tensor_mapping[source]
        return source

    def _rewire_layers(self, layers: dict, tensor_mapping: dict) -> None:
        """Update layer inputs and outputs of individual layers, following tensor remapping."""
        for layer in layers.values():
            new_inputs = [
                self._follow_tensor_mapping(inp, tensor_mapping) for inp in layer.inputs
            ]
            if new_inputs != list(layer.inputs):
                object.__setattr__(layer, "inputs", tuple(new_inputs))

            new_outputs = [
                self._follow_tensor_mapping(out, tensor_mapping)
                for out in layer.outputs
            ]
            if new_outputs != list(layer.outputs):
                object.__setattr__(layer, "outputs", tuple(new_outputs))

    def _remap_network_outputs(self, tensor_mapping: dict) -> list:
        """Remap network output tensors, i.e. updates the final network output tensor list."""
        new_outputs = []

        for out in self.ir.output_tensors:
            remapped = self._follow_tensor_mapping(out, tensor_mapping)
            new_outputs.append(remapped)

            if remapped != out:
                logger.info(f"Remapped network output: {out} -> {remapped}")

        return new_outputs

    def _rebuild_graph_structure(self, layers: dict) -> tuple[dict, dict]:
        """
        Rebuild tensor producer/consumer maps.

        Returns:
            (tensor_producers, tensor_consumers) tuple
        """
        tensor_producers = {}
        tensor_consumers = defaultdict(list)

        for layer in layers.values():
            for inp in layer.inputs:
                tensor_consumers[inp].append(layer.name)
            for out in layer.outputs:
                tensor_producers[out] = layer.name

        return tensor_producers, dict(tensor_consumers)

    def _renumber_layer_ids(self, layers: dict, execution_order: list) -> dict:
        """Renumber layer IDs to be sequential based on execution order."""
        new_layers = {}
        for new_id, layer_name in enumerate(execution_order):
            layer = layers[layer_name]
            # Update layer_id using frozen dataclass workaround
            object.__setattr__(layer, "layer_id", new_id)
            new_layers[layer_name] = layer
        return new_layers

    def _rebuild_ir(self, removed_layers: set, tensor_mapping: dict) -> NetworkIR:
        """Rebuild IR with removed layers and rewired tensors.

        Args:
            removed_layers: Set of layer names to remove.
            tensor_mapping: Dict mapping old tensor names to new tensor names.
        Returns:
            Rebuilt NetworkIR with layers removed and tensors rewired.
        """

        # 1. Remove layers
        new_layers = self._filter_removed_layers(removed_layers)

        # 2. Rewire tensor references in remaining layers
        self._rewire_layers(new_layers, tensor_mapping)

        # 3. Remap network outputs
        new_output_tensors = self._remap_network_outputs(tensor_mapping)

        # 4. Rebuild graph structure
        new_tensor_producers, new_tensor_consumers = self._rebuild_graph_structure(
            new_layers
        )

        # 5. Rebuild execution order
        new_execution_order = topological_sort(
            new_layers, new_tensor_producers, self.ir.input_tensors
        )

        # 6. Renumber layer IDs sequentially
        new_layers = self._renumber_layer_ids(new_layers, new_execution_order)

        return NetworkIR(
            layers=new_layers,
            execution_order=new_execution_order,
            tensor_producers=new_tensor_producers,
            tensor_consumers=new_tensor_consumers,
            input_tensors=self.ir.input_tensors,
            output_tensors=tuple(new_output_tensors),
        )
