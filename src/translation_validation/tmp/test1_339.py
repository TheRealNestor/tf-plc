from numpy import exp

def NeuralNetworkFB(input_data):
    output_data = [0.0] * 3  # output variable
    weights_0 = [0.003627, -0.250082, -0.135805, -0.175132, -0.022045, 0.041353, 0.195200, -0.060282, 0.106002, -0.116383, 0.131253, 0.155765, -0.324409, 0.091906, -0.096856, 0.041523, -0.013514, 0.012928, 0.143508, 0.194657, 0.028684, -0.051785, -0.164223, -0.051269, -0.464118, 0.123184, -0.326355, -0.094843, -0.201765, -0.083345, 0.057849, -0.114306, 0.028282, 0.150002, 0.049320, 0.007441, -0.044756, 0.042987, -0.259934, 0.116996, -0.110897, -0.080693, 0.054160, -0.088875, 0.467353, -0.028855, 0.060292, 0.115913, 0.001202, 0.277163, -0.005276, 0.263779, 0.099162, -0.164898, 0.394550, 0.029015, -0.058835, 0.000328, 0.284024, -0.215552, 0.246253, 0.059827, -0.073282, 0.213839, -0.132627, -0.687552, -0.212495, 0.074070, 0.203016, 0.473652, -0.589342, 0.330777, 0.226526, -0.059523, -0.408795, -0.228073, -0.276878, 0.102137, -0.161366, -0.377907]  # constant variable
    bias_0 = [2.120249, -0.078356, 2.330986, -2.026691, -2.665518, -2.475714, 2.031618, -3.335450, -0.510787, 1.237678, -0.587260, 1.120412, 0.940391, -2.704393, 2.811770, 1.830337]  # constant variable
    weights_1 = [-0.830586, 0.088781, -0.814987, 0.085001, -0.023562, -1.021089, 0.673023, -0.194144, -1.001580, -1.299681, -0.795840, -0.155841, -0.465572, 0.019149, -0.146256, -0.062395, 0.017692, -0.551936, 0.172132, -0.396230, -0.505784, -0.054301, -0.303767, -0.276629, -0.032041, 0.209220, 0.000904, 0.051964, 0.016328, -0.136356, 0.275315, -0.362574, -0.035504, -0.975341, -0.179583, -0.019616, -0.043657, -0.093864, -0.045327, -0.132138, -0.262940, 0.032698, -0.120669, 0.037618, -0.059490, -0.002911, 0.357226, -0.016140, -0.039667, -0.382554, -0.081817, -0.884051, -0.770900, 0.035414, 0.526383, -0.067905, 0.519444, -0.005429, -0.091049, -0.078673, 0.357013, -0.323569, -0.083871, -0.330384, -0.256357, 0.018025, -0.136537, 0.014780, -0.078766, 0.008493, -0.054446, -0.048947, -0.121211, 0.083447, -0.089039, 0.010245, 0.030062, -0.198294, 0.045321, -0.057408, -0.393048, -1.050970, -0.302898, -0.713254, -0.091482, -0.416536, 0.473784, -0.390989, -0.322377, -0.017674, -0.674114, 0.237670, 0.014548, -0.003168, -0.081556, -0.062491, -0.450305, 0.036272, 0.136842, 0.042255, -0.025277, 0.103230, 0.069847, -0.187537, 0.174698, -0.315423, 0.225650, -0.028352, 0.036447, 0.228958, 0.313116, -0.062415, 0.035593, -0.078813, 0.304152, -0.025866, 0.141586, -0.163367, -0.029946, -0.167942, -0.021319, 0.023250, -0.087139, 0.076556, -0.039450, -0.662014, -0.127649, 0.013737, -0.288936, -0.241115, -0.247504, -0.171833, -0.428070, -0.003751, -0.081004, 0.022675, -0.011180, -0.386573, 0.201129, -0.687217, -0.282010, -0.410747, -0.366362, -0.018255, -0.112794, -0.043326, -0.182112, 0.064784, -0.023184, 0.192958, -0.044890, -0.105098, 0.002412, 0.090593, -0.418685, 0.008538, -0.080098, -0.302576, -0.281730, 0.067629, -0.521312, 0.138073, -0.070572, 0.463414, 0.202859, -0.005036, -0.074766, -0.388101, -0.600596, 0.122237, -0.192517, 0.072023, 0.034247, -0.639483, 0.386060, -0.473677, -0.024248, -0.988183, -0.328465, -0.205916, -0.008701, 0.248460, 0.031325, 0.096932, 0.019512, -0.046507, -0.220687, -0.060929, -0.038850, -0.767569, -0.455635, 0.034634]  # constant variable
    bias_1 = [-1.215442, 1.598357, -1.555748, 2.049722, 1.638338, 1.093843, -0.321076, -1.514364, -1.043459, 1.810597, -1.634270, 2.099920]  # constant variable
    weights_2 = [0.068431, -0.184586, 0.321569, 0.294753, -0.119050, 0.070810, -0.330731, -0.524437, -0.205982, 0.603575, 0.006964, 0.184631, 0.607389, -0.366200, -0.267226, -0.254573, 0.053714, 0.287706, 0.095947, -0.328237, 0.022823, 0.080915, -0.193581, 0.141749, 0.089687, -0.041353, 0.262366, -0.750981, 0.364863, 0.484818, -0.199030, -0.562888, -0.083594, -0.080012, 0.267366, -1.069590]  # constant variable
    bias_2 = [-0.748827, 0.910146, -0.410649]  # constant variable
    buffer_0 = [0.0] * 12  # var variable
    buffer_1 = [0.0] * 16  # var variable
    i = 0  # var variable
    j = 0  # var variable
    sum = 0.0  # var variable
    max_val = 0.0  # var variable
    exp_sum = 0.0  # var variable

    # Layer 0: Fused Linear + RELU
    for j in range(0, 15 + 1):
        sum = 0.0
        for i in range(0, 4 + 1):
            sum = sum + input_data[i] * weights_0[i * 16 + j]
        buffer_1[j] = max(sum + bias_0[j], 0.0)
    # Layer 1: Fused Linear + RELU
    for j in range(0, 11 + 1):
        sum = 0.0
        for i in range(0, 15 + 1):
            sum = sum + buffer_1[i] * weights_1[i * 12 + j]
        buffer_0[j] = max(sum + bias_1[j], 0.0)
    # Layer 2: Fused Linear + SOFTMAX
    for j in range(0, 2 + 1):
        sum = 0.0
        for i in range(0, 11 + 1):
            sum = sum + buffer_0[i] * weights_2[i * 3 + j]
        output_data[j] = sum + bias_2[j]
    max_val = output_data[0]
    for i in range(1, 2 + 1):
        if output_data[i] > max_val:
            max_val = output_data[i]
    exp_sum = 0.0
    for i in range(0, 2 + 1):
        output_data[i] = exp(output_data[i] - max_val)
        exp_sum = exp_sum + output_data[i]
    for i in range(0, 2 + 1):
        output_data[i] = output_data[i] / exp_sum

    return output_data